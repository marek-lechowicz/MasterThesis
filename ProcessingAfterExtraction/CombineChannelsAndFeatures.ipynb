{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle2\\features\\coif1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle2\\features\\coif5\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle2\\features\\db1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle2\\features\\rbio6_8\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle3\\features\\coif1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle3\\features\\coif5\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle3\\features\\db1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\dalle3\\features\\rbio6_8\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\firefly\\features\\coif1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\firefly\\features\\coif5\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\firefly\\features\\db1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\firefly\\features\\rbio6_8\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\glide\\features\\coif1\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\glide\\features\\coif5\\train_test\n",
      "R: Series([], Name: R_Image, dtype: object)\n",
      "G: Series([], Name: G_Image, dtype: object)\n",
      "B: Series([], Name: B_Image, dtype: object)\n",
      "../data/features/synthbuster/wavelet1\\glide\\features\\db1\\train_test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gen_image_path = '../data/features/synthbuster/wavelet1'\n",
    "\n",
    "for gen in os.listdir(gen_image_path):\n",
    "    features_path = os.path.join(gen_image_path, gen, 'features')\n",
    "    for dir in os.listdir(features_path):\n",
    "        # to allow to re-run the script without manually deleting the files\n",
    "        if dir == \"all_wavelets\":\n",
    "            continue\n",
    "        for dataset in os.listdir(os.path.join(features_path, dir)):\n",
    "            path = os.path.join(features_path, dir, dataset)\n",
    "            # Read R features from RGB_features folder\n",
    "            R = pd.read_csv(os.path.join(path, 'features_red.csv'), index_col=0)\n",
    "            G = pd.read_csv(os.path.join(path, 'features_green.csv'), index_col=0)\n",
    "            B = pd.read_csv(os.path.join(path, 'features_blue.csv'), index_col=0)\n",
    "\n",
    "            # Add R prefix to all columns in R_test_features\n",
    "            R = R.add_prefix('R_')\n",
    "            G = G.add_prefix('G_')\n",
    "            B = B.add_prefix('B_')\n",
    "            \n",
    "            # print filenames with nan values\n",
    "            print('R:', R[R.isnull().any(axis=1)]['R_Image'])\n",
    "            print('G:', G[G.isnull().any(axis=1)]['G_Image'])\n",
    "            print('B:', B[B.isnull().any(axis=1)]['B_Image'])\n",
    "\n",
    "            # Delete Image, Mask and Category columns from G and B\n",
    "            G = G.drop(columns=['G_Image', 'G_Mask', 'G_Category'])\n",
    "            B = B.drop(columns=['B_Image', 'B_Mask', 'B_Category'])\n",
    "\n",
    "            # Remove R_ prefix from R_Image, R_Mask and R_Category columns in R\n",
    "            R = R.rename(columns={'R_Image': 'Image', 'R_Mask': 'Mask', 'R_Category': 'Category'})\n",
    "\n",
    "            # Merge R, G and B features\n",
    "            RGB = pd.concat([R, G, B], axis=1)\n",
    "\n",
    "            # Modify Image and Mask columns to leave only the file name and the nearest parent folder\n",
    "            # remove R_ prefix from file names\n",
    "            RGB['Image'] = RGB['Image'].str.replace('R_', '')\n",
    "            RGB['Image'] = RGB['Image'].apply(lambda x: x.split('/')[-3] + '/' + x.split('/')[-2] + '/' + x.split('/')[-1])\n",
    "            RGB['Mask'] = RGB['Mask'].apply(lambda x: x.split('/')[-1:][0])\n",
    "            RGB.head()\n",
    "            print(path)\n",
    "            # Save RGB features\n",
    "            RGB.to_csv(os.path.join(path, 'features_RGB.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining wavelet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "gen_image_path = '../data/features/synthbuster/wavelet1'\n",
    "\n",
    "for gen in os.listdir(gen_image_path):\n",
    "    features_path = os.path.join(gen_image_path, gen, 'features')\n",
    "\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    # we are first iterating over datasets (test, train etc.) because we want to merge all wavelet features for each dataset\n",
    "    for dataset in os.listdir(os.path.join(features_path, dir)):\n",
    "        \n",
    "        for dir in os.listdir(features_path):\n",
    "            # to allow to re-run the script without manually deleting the files\n",
    "            if dir == \"all_wavelets\":\n",
    "                continue\n",
    "            \n",
    "            path = os.path.join(features_path, dir, dataset)\n",
    "            \n",
    "            # read RGB features\n",
    "            df = pd.read_csv(os.path.join(path, 'features_RGB.csv'), index_col=0)\n",
    "            \n",
    "            # drop diagnostics, 'Image', 'Mask' and 'Category' columns\n",
    "            to_drop = list()\n",
    "            for column in df.columns:\n",
    "                if dir != 'coif1' and ('diagnostics' in column or column == 'Image' or column == 'Category' or column == 'Mask'):\n",
    "                    to_drop.append(column)\n",
    "                elif 'diagnostics' in column:\n",
    "                    to_drop.append(column)\n",
    "                    \n",
    "            df.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "            # add prefix to all columns\n",
    "            df = df.add_prefix(f'{dir}_')\n",
    "            \n",
    "            # Merge RGB features with df_train and df_test\n",
    "            if dataset == 'train' or dataset == 'train_test':\n",
    "                df_train = pd.concat([df_train, df], axis=1)\n",
    "            elif dataset == 'test' or dataset == 'val':\n",
    "                df_test = pd.concat([df_test, df], axis=1)\n",
    "            \n",
    "        # Save df_train and df_test\n",
    "        os.makedirs(os.path.join(features_path, 'all_wavelets', dataset), exist_ok=True)\n",
    "        df_train.to_csv(os.path.join(features_path, 'all_wavelets', dataset, 'features_RGB.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concantenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dalle2\n",
      "Processing dalle3\n",
      "Processing firefly\n",
      "Processing glide\n",
      "Processing img\n",
      "Processing midjourney-v5\n",
      "Processing stable-diffusion-1-3\n",
      "Processing stable-diffusion-1-4\n",
      "Processing stable-diffusion-2\n",
      "Processing stable-diffusion-xl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "gen_image_path = '../data/features/synthbuster/wavelet1'\n",
    "gen_standard_path = '../data/features/synthbuster/standard'\n",
    "combined_path = '../data/features/synthbuster/combined'\n",
    "\n",
    "for gen in os.listdir(gen_image_path):\n",
    "    \n",
    "    print(f\"Processing {gen}\")\n",
    "    \n",
    "    features_path = os.path.join(gen_image_path, gen, 'features', 'all_wavelets')\n",
    "    standard_features_path = os.path.join(gen_standard_path, gen, 'features', 'extraction_params')\n",
    "       \n",
    "    for dataset in os.listdir(standard_features_path):\n",
    "        df_train = pd.read_csv(os.path.join(features_path, dataset, 'features_RGB.csv'), index_col=0)\n",
    "        train_main = pd.read_csv(os.path.join(standard_features_path, dataset, 'features_RGB.csv'), index_col=0)\n",
    "        \n",
    "        # drop wavelet columns to avoid duplicates\n",
    "        to_drop = list()\n",
    "        for column in train_main.columns:\n",
    "            if 'wavelet' in column:\n",
    "                to_drop.append(column)       \n",
    "        train_main.drop(to_drop, axis=1, inplace=True)    \n",
    "        df_train.drop(columns=df_train.select_dtypes(include=['object']).columns, inplace=True)\n",
    "        combined_train = pd.concat([train_main, df_train], axis=1)     \n",
    "        os.makedirs(os.path.join(combined_path, gen, dataset), exist_ok=True)\n",
    "        combined_train.to_csv(os.path.join(combined_path, gen, dataset, 'features_RGB.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
